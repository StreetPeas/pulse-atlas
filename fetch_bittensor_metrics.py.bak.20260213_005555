#!/usr/bin/env python3
"""
–°–±–æ—Ä –±–∞–∑–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫ –∏–∑ —Å–µ—Ç–∏ Bittensor —á–µ—Ä–µ–∑ SubtensorAPI.

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Bittensor SDK –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–º–µ—Ä–∞ —Ç–µ–∫—É—â–µ–≥–æ –±–ª–æ–∫–∞,
–∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö –º–µ—Ö–∞–Ω–∏–∑–º–æ–≤ –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —ç–º–∏—Å—Å–∏–∏ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ
—Å–∞–±–Ω–µ—Ç–∞ (netuid). –ü–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ —Ç–∞–±–ª–∏—Ü—É `signals`
–∏—Å–ø–æ–ª—å–∑—É—è —Ñ—É–Ω–∫—Ü–∏—é `save_signal()` –∏–∑ –≤–∞—à–µ–≥–æ –º–æ–¥—É–ª—è signals. –£—Ä–æ–≤–µ–Ω—å
—Å–∏–≥–Ω–∞–ª–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî üü°, –≥–æ—Ä–∏–∑–æ–Ω—Ç ‚Äî T2.
"""
from __future__ import annotations

import os, sys
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
import os
import json
from typing import Any, Dict

try:
    import bittensor as bt
except ImportError as e:
    raise SystemExit(
        "–û—à–∏–±–∫–∞: –ø–∞–∫–µ—Ç 'bittensor' –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –µ–≥–æ —Å –ø–æ–º–æ—â—å—é 'python3 -m pip install bittensor'."
    ) from e

try:
    # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ signals.py –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ PYTHONPATH –∏–ª–∏ –≤ —Ç–æ–º –∂–µ –∫–∞—Ç–∞–ª–æ–≥–µ
    from storage import save_signal
except ImportError:
    raise SystemExit(
        "–û—à–∏–±–∫–∞: –º–æ–¥—É–ª—å 'signals' –Ω–µ –Ω–∞–π–¥–µ–Ω. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª signals.py –Ω–∞—Ö–æ–¥–∏—Ç—Å—è —Ä—è–¥–æ–º —Å–æ —Å–∫—Ä–∏–ø—Ç–æ–º –∏–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω –≤ PYTHONPATH."
    )

def fetch_bittensor_metrics(netuid: int = 1) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ —Å–µ—Ç–∏ Bittensor."""
    sub = bt.SubtensorApi()
    metrics: Dict[str, Any] = {}
    try:
        current_block: int = sub.block  # —Ç–µ–∫—É—â–∏–π –Ω–æ–º–µ—Ä –±–ª–æ–∫–∞
        metrics["block"] = current_block
    except Exception as e:
        metrics["block_error"] = str(e)
    try:
        mech_count: int = sub.subnets.get_mechanism_count(netuid=netuid)
        metrics["mechanism_count"] = mech_count
    except Exception as e:
        metrics["mechanism_count_error"] = str(e)
    try:
        split = sub.subnets.get_mechanism_emission_split(netuid=netuid)
        total = sum(split) if split else 0
        emissions = [round(x / total, 4) for x in split] if total else []
        metrics["emission_split"] = emissions
    except Exception as e:
        metrics["emission_split_error"] = str(e)
    return metrics

# --- ATLAS PATCH: metrics -> SQLite ---
import sqlite3
import json
from datetime import datetime, timezone

def _atlas_db_path() -> str:
    from pathlib import Path as _P
    return str(_P(__file__).resolve().parent / "data" / "atlas.db")

def _insert_signal_row(row: dict) -> None:
    db = _atlas_db_path()
    conn = sqlite3.connect(db)
    try:
        cur = conn.cursor()
        info = cur.execute("PRAGMA table_info(signals)").fetchall()
        cols = [r[1] for r in info]
        notnull = {r[1]: int(r[3]) for r in info}        # name -> 0/1
        dflt    = {r[1]: r[4] for r in info}             # name -> default sql literal or None

        # meta -> json string (–µ—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∞ –µ—Å—Ç—å)
        if "meta" in cols and "meta" in row and not isinstance(row["meta"], str):
            row["meta"] = json.dumps(row["meta"], ensure_ascii=False)

        # --- –ê–≤—Ç–æ–∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ NOT NULL (–≥–ª–∞–≤–Ω–æ–µ: label/source/color –∏ —Ç.–¥.) ---
        # –ë–∞–∑–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        base_source = row.get("source") or row.get("origin") or row.get("project") or "bittensor"
        base_label  = row.get("label")  or row.get("project") or base_source or "bittensor"
        base_text   = row.get("text")   or ""
        base_title  = row.get("title")  or base_label
        base_ts     = row.get("ts")     or datetime.now(timezone.utc).isoformat()

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —á–∞—Å—Ç—ã–µ –ø–æ–ª—è
        if "ts" in cols and "ts" not in row:
            row["ts"] = base_ts
        if "source" in cols and "source" not in row:
            row["source"] = base_source
        if "label" in cols and "label" not in row:
            row["label"] = base_label
        if "title" in cols and "title" not in row:
            row["title"] = base_title
        if "text" in cols and "text" not in row:
            row["text"] = base_text

        # –ü–æ–ª—è, –∫–æ—Ç–æ—Ä—ã–µ —á–∞—Å—Ç–æ NOT NULL –≤ —Ç–≤–æ–µ–π —Å—Ö–µ–º–µ
        defaults = {
            "color":   "white",          # –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π (–ø–æ–¥ —Ç–≤–æ–π –≤—ã–≤–æ–¥ —Ç–æ—á–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ)
            "level":   "<0001f7e1>",
            "horizon": "T2",
            "kind":    row.get("kind") or "metric",
            "url":     "",
            "sentiment": "neutral",
            "score":   0.35,
            "summary": base_text or base_title,
            "origin":  row.get("origin") or "bittensor",
            "project": row.get("project") or "bittensor",
        }
        for k, v in defaults.items():
            if k in cols and k not in row:
                row[k] = v

        # –ï—Å–ª–∏ –≤—Å—ë –µ—â—ë –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –∫–∞–∫–∏—Ö-—Ç–æ NOT NULL –∫–æ–ª–æ–Ω–æ–∫ ‚Äî –ø–æ–¥—Å—Ç–∞–≤–∏–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –∑–∞–≥–ª—É—à–∫–∏
        for c in cols:
            if c == "id":
                continue
            if notnull.get(c, 0) == 1 and (c not in row or row[c] is None):
                # –µ—Å–ª–∏ –≤ —Ç–∞–±–ª–∏—Ü–µ –µ—Å—Ç—å DEFAULT ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–≥–æ (–∫–∞–∫ —Ç–µ–∫—Å—Ç)
                if dflt.get(c) is not None:
                    # dflt –ø—Ä–∏—Ö–æ–¥–∏—Ç SQL-–ª–∏—Ç–µ—Ä–∞–ª–æ–º, –æ—Å—Ç–∞–≤–∏–º –∫–∞–∫ —Å—Ç—Ä–æ–∫—É; —á–∞—â–µ –≤—Å–µ–≥–æ –æ–∫
                    row[c] = str(dflt[c]).strip("'")
                else:
                    # —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –ø–æ –∏–º–µ–Ω–∏
                    if c in ("ts",):
                        row[c] = base_ts
                    elif c in ("label",):
                        row[c] = base_label
                    elif c in ("source",):
                        row[c] = base_source
                    elif c in ("title",):
                        row[c] = base_title
                    elif c in ("text", "summary", "url"):
                        row[c] = ""
                    elif c in ("score",):
                        row[c] = 0.0
                    else:
                        row[c] = ""

        insert_cols = [c for c in cols if c != "id" and c in row]
        if not insert_cols:
            raise RuntimeError("signals table: no matching columns to insert")
        sql = "INSERT OR IGNORE INTO signals ({}) VALUES ({})".format(
            ",".join(insert_cols),
            ",".join(["?"] * len(insert_cols)),
        )
        cur.execute(sql, [row[c] for c in insert_cols])
        conn.commit()
    finally:
        conn.close()

def save_bittensor_metrics_sqlite(metrics, netuid: int = 1) -> None:
    # --- ATLAS: metrics gate (save every N blocks) ---
    import sqlite3, re as _re
    from pathlib import Path as _Path

    ATLAS_METRICS_STEP = 10  # <-- –ø–æ–º–µ–Ω—è–π, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ

    _db_path = _Path("data/atlas.db")
    _con = sqlite3.connect(_db_path)
    _cur = _con.cursor()
    _row_last = _cur.execute(
        """
        SELECT url
        FROM signals
        WHERE url LIKE ?
        ORDER BY id DESC
        LIMIT 1
        """,
        (f"bt://metrics/netuid={netuid}/block=%",),
    ).fetchone()

    ts = datetime.now(timezone.utc).isoformat()
    title = f"Bittensor metrics (netuid={netuid})"
    text = json.dumps(metrics, ensure_ascii=False, indent=2)

    row = {
        "ts": ts,
        "origin": "bittensor",
        "project": "bittensor",
        "kind": "metric",
        "title": title,
    "url": f"bt://metrics/netuid={netuid}/block={metrics.get('block', '')}",
    "source": "bittensor",
    "label": "bittensor",
    "color": "neutral",
    "sentiment": "neutral",
    "score": 0.35,
        "text": text,
        "meta": {"netuid": netuid, "metrics": metrics},
    }
    # --- ATLAS: gate metrics frequency (save every N blocks) ---
    import sqlite3, re
    from pathlib import Path
    ATLAS_METRICS_STEP = 10  # save once per N blocks

    _last_block = None
    con = None
    try:
        con = sqlite3.connect(Path("data/atlas.db"))
        cur = con.cursor()
        row_last = cur.execute(
            """
            SELECT url
            FROM signals
            WHERE url LIKE ?
            ORDER BY id DESC
            LIMIT 1
            """,
            (f"bt://metrics/netuid={netuid}/block=%",),
        ).fetchone()
    finally:
        if con is not None:
            con.close()

    if row_last and row_last[0]:
        mm = re.search(r"block=(\d+)", row_last[0])
        if mm:
            _last_block = int(mm.group(1))

    _cur_block = int(metrics.get("block", 0) or 0)
    if _last_block is not None and _cur_block < _last_block + ATLAS_METRICS_STEP:
        print(f"Skip metrics: block {_cur_block} (last {_last_block}, step {ATLAS_METRICS_STEP})")
        return
    # --- /ATLAS ---
    _insert_signal_row(row)
# --- /ATLAS PATCH ---

def main() -> None:
    netuid = int(os.environ.get("BT_NETUID", 1))
    metrics = fetch_bittensor_metrics(netuid=netuid)
    save_bittensor_metrics_sqlite(metrics, netuid=netuid)
    print(f"–ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è netuid={netuid} —Å–æ–±—Ä–∞–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:\\n{json.dumps(metrics, ensure_ascii=False, indent=2)}")

if __name__ == "__main__":
    main()
